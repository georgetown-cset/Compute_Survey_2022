{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HgLIoZ3hSWws"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "\n",
        "from scipy.stats import mannwhitneyu, spearmanr, t, chisquare\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import seaborn as sns\n",
        "from matplotlib.patches import ConnectionPatch\n",
        "from matplotlib.collections import PatchCollection\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "from matplotlib.colors import to_rgba\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "sns.set_style('darkgrid')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "lLFfZRiicQNR",
        "outputId": "9ea0fb91-9cd5-454c-85a2-f6255ccbcfd7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-85baba4b-b988-4f6f-a8a7-dd7fb9cd5fbf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-85baba4b-b988-4f6f-a8a7-dd7fb9cd5fbf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving all_data.csv to all_data (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data cleaning"
      ],
      "metadata": {
        "id": "RNhCo0jZtP6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('all_data.csv')\n",
        "\n",
        "\n",
        "# Filter out non-consents and people who indicating spending no time working on AI systems\n",
        "df['Screener'] = pd.to_numeric(df.Screener, errors = 'coerce')\n",
        "df = df[(df.Consent == 1) & (df.Screener > 0)]\n",
        "\n",
        "# Drop unneeded columns\n",
        "df.drop(columns=['StartDate', 'EndDate', 'Status', 'RecordedDate', 'UserLanguage', 'sig_year_5_TEXT',\n",
        "                 'comp_year_5_TEXT', 'Consent', 'more_thoughts'], inplace=True)\n",
        "\n",
        "# Ignore \"I don't know\" responses for cost and GPU-hours\n",
        "df['CompCost'] = df.CompCost.apply(lambda x: pd.NA if x == \"6\" else x)\n",
        "df['CompGPUs'] = df.CompGPUs.apply(lambda x: pd.NA if x == \"7\" else x)\n",
        "df['SigCost'] = df.SigCost.apply(lambda x: pd.NA if x == \"6\" else x)\n",
        "df['SigGPUs'] = df.SigGPUs.apply(lambda x: pd.NA if x == \"7\" else x)\n",
        "\n",
        "# All columns currently have numeric data but are recorded as strings -- convert them all\n",
        "for column in df.columns[5:]:\n",
        "    df[column] = pd.to_numeric(df[column], errors = 'coerce')\n",
        "\n",
        "# Set the values for \"sector\" to their text meanings\n",
        "sector_values = {0: 'Academia', 1: 'Industry', 2: 'Government', 3: 'Other'}\n",
        "df['Sector'] = df.Sector.apply(lambda x: sector_values[x] if x in sector_values else pd.NA)\n",
        "\n",
        "# Set the values for \"company size\" to their text meanings\n",
        "size_values = {0: '<50 Employees', 1: '50-100 Employees', 2: '101-500 Employees', 3: '>500 Employees'}\n",
        "df['CompanySize'] = df.CompanySize.apply(lambda x: size_values[x] if x in sector_values else pd.NA)\n",
        "\n",
        "# Create a new column called \"PrioritySimplified\" and set values for \"TopPriority\" to text values\n",
        "priorities = {0: 'Collecting more data', 1: 'Refining or cleaning data', 2: 'Purchasing more or higher-quality compute',\n",
        "             3: 'Hiring more programmers or engineers', 4: 'Hiring researchers', 5: 'Doing more evaluation or testing'}\n",
        "df['TopPriority'] = df.TopPriority.map(priorities)\n",
        "simplified = {'Collecting more data': 'Data', 'Refining or cleaning data': 'Data',\n",
        "             'Hiring researchers': 'Talent', 'Hiring more programmers or engineers': 'Talent',\n",
        "             'Purchasing more or higher-quality compute': 'Compute',\n",
        "             'Doing more evaluation or testing': 'Evaluation'}\n",
        "df['PrioritySimplified'] = df.TopPriority.map(simplified)\n",
        "\n",
        "# If the most significant project was also the most compute-intensive, duplicate the answers to both columns\n",
        "df['CompCost'] = df.apply(lambda x: x['CompCost'] if x['SameProject'] == 0. else x['SigCost'], axis=1)\n",
        "df['CompGPUs'] = df.apply(lambda x: x['CompGPUs'] if x['SameProject'] == 0. else x['SigGPUs'], axis=1)\n",
        "df['CompTeamSize'] = df.apply(lambda x: x['CompTeamSize'] if x['SameProject'] == 0. else x['SigTeamSize'], axis=1)\n",
        "df['CompYear'] = df.apply(lambda x: x['CompYear'] if x['SameProject'] == 0. else x['SigYear'], axis=1)\n",
        "df['CompComponent'] = df.apply(lambda x: x['CompComponent'] if x['SameProject'] == 0. else x['SigComponent'], axis=1)\n",
        "\n",
        "# Create separate dfs for different subsets of data\n",
        "all_responses = df.copy()\n",
        "no_snowball = df[df.DistributionChannel == 'email'].copy()\n",
        "completed = df[df.Finished == 1].copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AYvJTE4basA",
        "outputId": "ad2389ce-3b66-49de-a8fd-0ba93e513313"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-5b9b2a5ca464>:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['PrioritySimplified'] = df.TopPriority.map(simplified)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Identify which data version we're using"
      ],
      "metadata": {
        "id": "uVWCN7V3taLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "version = no_snowball\n",
        "# version = all_responses\n",
        "# version = completed"
      ],
      "metadata": {
        "id": "d3_dj8Jxtd_9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## High Compute Users"
      ],
      "metadata": {
        "id": "rlrgR-2Be6jV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How many high compute users are there, defined by GPUs\n",
        "high_compute_users = version[version.CompGPUs >= 4]\n",
        "print(f\"There are {len(high_compute_users)} high compute users (>5000 GPU hours).\")\n",
        "low_compute_users = version[version.CompGPUs <= 1]\n",
        "print(f\"There are {len(low_compute_users)} low compute users (<=50 GPU hours).\")\n",
        "print()\n",
        "for want in [\"WantsCompute\", \"WantsData\", \"WantsStaff\", \"WantsGrants\", \"WantsStandards\"]:\n",
        "  print(f\"{len(high_compute_users[high_compute_users[want] == 1])} high compute users {want} and {len(low_compute_users[low_compute_users[want] == 1])} low compute users {want}\")\n",
        "  print(f\"{(len(high_compute_users[high_compute_users[want] == 1])/len(high_compute_users))*100:.2f}% of high compute users {want} and {(len(low_compute_users[low_compute_users[want] == 1])/len(low_compute_users))*100:.2f}% of low compute users {want}\")\n",
        "  print()\n",
        "print(\"-----\\n\")\n",
        "for field in [\"CV\", \"NLP\", \"Robotics\", \"RL\", \"Other\"]:\n",
        "  print(f\"The # of high compute users in {field} is {len(high_compute_users[high_compute_users[field] == 1])} and the # of low compute users is {len(low_compute_users[low_compute_users[field] == 1])}\")\n",
        "  print(f\"The % of high compute users in {field} is {(len(high_compute_users[high_compute_users[field] == 1])/len(high_compute_users))*100:.2f}% and the % of low compute users is {(len(low_compute_users[low_compute_users[field] == 1])/len(low_compute_users))*100:.2f}%\")\n",
        "  print()\n",
        "print(\"-----\\n\")\n",
        "for subfield in [\"RecommenderSystems\", \"Speech\", \"TimeSeriesData\", \"MusicAndAudio\", \"GraphAnalysis\", \"AlgorithmicOrArchitectureAnalysis\", \"NoneofThese\"]:\n",
        "  print(f\"The # of high compute users in {subfield} is {len(high_compute_users[high_compute_users[subfield] == 1])} and the # of low compute users is {len(low_compute_users[low_compute_users[subfield] == 1])}\")\n",
        "  print(f\"The % of high compute users in {subfield} is {(len(high_compute_users[high_compute_users[subfield] == 1])/len(high_compute_users))*100:.2f}% and the % of low compute users is {(len(low_compute_users[low_compute_users[subfield] == 1])/len(low_compute_users))*100:.2f}%\")\n",
        "  print()\n",
        "print(\"-----\\n\")\n",
        "for sector in [\"Academia\", \"Industry\"]:\n",
        "  print(f\"The # of high compute users in {sector} is {len(high_compute_users[high_compute_users.Sector == sector])} and the # of low computer users is {len(low_compute_users[low_compute_users.Sector == sector])}\")\n",
        "  print(f\"The % of high compute users in {sector} is {(len(high_compute_users[high_compute_users.Sector == sector])/len(version[version.Sector == sector]))*100:.2f}% and the % of low compute users is {(len(low_compute_users[low_compute_users.Sector == sector])/len(version[version.Sector == sector]))*100:.2f}%\")\n",
        "  print(f\"The % of {sector} respondents among high compute users is {(len(high_compute_users[high_compute_users.Sector == sector])/len(high_compute_users))*100:.2f}% and the % of {sector} respondents among low compute users is {(len(low_compute_users[low_compute_users.Sector == sector])/len(low_compute_users))*100:.2f}%\")\n",
        "print(\"\\n-----\\n\")\n",
        "highest_compute_users = version[version.CompGPUs >= 6]\n",
        "for sector in [\"Academia\", \"Industry\"]:\n",
        "  print(f\"The # of highest compute users in {sector} is {len(highest_compute_users[highest_compute_users.Sector == sector])}\")\n",
        "  print(f\"The % of {sector} respondents among highest compute users is {(len(highest_compute_users[highest_compute_users.Sector == sector])/len(highest_compute_users))*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4VPVJfYcncq",
        "outputId": "a101d432-37b4-41f9-f2ec-fb642f02a027"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 88 high compute users (>5000 GPU hours).\n",
            "There are 70 low compute users (<=50 GPU hours).\n",
            "\n",
            "64 high compute users WantsCompute and 37 low compute users WantsCompute\n",
            "72.73% of high compute users WantsCompute and 52.86% of low compute users WantsCompute\n",
            "\n",
            "47 high compute users WantsData and 32 low compute users WantsData\n",
            "53.41% of high compute users WantsData and 45.71% of low compute users WantsData\n",
            "\n",
            "30 high compute users WantsStaff and 21 low compute users WantsStaff\n",
            "34.09% of high compute users WantsStaff and 30.00% of low compute users WantsStaff\n",
            "\n",
            "64 high compute users WantsGrants and 52 low compute users WantsGrants\n",
            "72.73% of high compute users WantsGrants and 74.29% of low compute users WantsGrants\n",
            "\n",
            "26 high compute users WantsStandards and 20 low compute users WantsStandards\n",
            "29.55% of high compute users WantsStandards and 28.57% of low compute users WantsStandards\n",
            "\n",
            "-----\n",
            "\n",
            "The # of high compute users in CV is 40 and the # of low compute users is 5\n",
            "The % of high compute users in CV is 45.45% and the % of low compute users is 7.14%\n",
            "\n",
            "The # of high compute users in NLP is 33 and the # of low compute users is 11\n",
            "The % of high compute users in NLP is 37.50% and the % of low compute users is 15.71%\n",
            "\n",
            "The # of high compute users in Robotics is 12 and the # of low compute users is 14\n",
            "The % of high compute users in Robotics is 13.64% and the % of low compute users is 20.00%\n",
            "\n",
            "The # of high compute users in RL is 16 and the # of low compute users is 15\n",
            "The % of high compute users in RL is 18.18% and the % of low compute users is 21.43%\n",
            "\n",
            "The # of high compute users in Other is 27 and the # of low compute users is 38\n",
            "The % of high compute users in Other is 30.68% and the % of low compute users is 54.29%\n",
            "\n",
            "-----\n",
            "\n",
            "The # of high compute users in RecommenderSystems is 2 and the # of low compute users is 12\n",
            "The % of high compute users in RecommenderSystems is 2.27% and the % of low compute users is 17.14%\n",
            "\n",
            "The # of high compute users in Speech is 2 and the # of low compute users is 1\n",
            "The % of high compute users in Speech is 2.27% and the % of low compute users is 1.43%\n",
            "\n",
            "The # of high compute users in TimeSeriesData is 11 and the # of low compute users is 12\n",
            "The % of high compute users in TimeSeriesData is 12.50% and the % of low compute users is 17.14%\n",
            "\n",
            "The # of high compute users in MusicAndAudio is 2 and the # of low compute users is 1\n",
            "The % of high compute users in MusicAndAudio is 2.27% and the % of low compute users is 1.43%\n",
            "\n",
            "The # of high compute users in GraphAnalysis is 8 and the # of low compute users is 8\n",
            "The % of high compute users in GraphAnalysis is 9.09% and the % of low compute users is 11.43%\n",
            "\n",
            "The # of high compute users in AlgorithmicOrArchitectureAnalysis is 14 and the # of low compute users is 18\n",
            "The % of high compute users in AlgorithmicOrArchitectureAnalysis is 15.91% and the % of low compute users is 25.71%\n",
            "\n",
            "The # of high compute users in NoneofThese is 6 and the # of low compute users is 11\n",
            "The % of high compute users in NoneofThese is 6.82% and the % of low compute users is 15.71%\n",
            "\n",
            "-----\n",
            "\n",
            "The # of high compute users in Academia is 53 and the # of low computer users is 49\n",
            "The % of high compute users in Academia is 19.34% and the % of low compute users is 17.88%\n",
            "The % of Academia respondents among high compute users is 60.23% and the % of Academia respondents among low compute users is 70.00%\n",
            "The # of high compute users in Industry is 26 and the # of low computer users is 13\n",
            "The % of high compute users in Industry is 21.67% and the % of low compute users is 10.83%\n",
            "The % of Industry respondents among high compute users is 29.55% and the % of Industry respondents among low compute users is 18.57%\n",
            "\n",
            "-----\n",
            "\n",
            "The # of highest compute users in Academia is 2\n",
            "The % of Academia respondents among highest compute users is 20.00%\n",
            "The # of highest compute users in Industry is 4\n",
            "The % of Industry respondents among highest compute users is 40.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many high compute users are there, defined by cost\n",
        "high_compute_cost_users = version[version.CompCost >= 4]\n",
        "print(f\"There are {len(high_compute_cost_users)} high compute users (>$100,000).\")\n",
        "low_compute_cost_users = version[version.CompCost <= 1]\n",
        "print(f\"There are {len(low_compute_cost_users)} low compute users (<=$1000).\")\n",
        "print()\n",
        "for want in [\"WantsCompute\", \"WantsData\", \"WantsStaff\", \"WantsGrants\", \"WantsStandards\"]:\n",
        "  print(f\"{len(high_compute_cost_users[high_compute_cost_users[want] == 1])} high compute users {want} and {len(low_compute_cost_users[low_compute_cost_users[want] == 1])} low compute users {want}\")\n",
        "  print(f\"{(len(high_compute_cost_users[high_compute_cost_users[want] == 1])/len(high_compute_cost_users))*100:.2f}% of high compute users {want} and {(len(low_compute_cost_users[low_compute_cost_users[want] == 1])/len(low_compute_cost_users))*100:.2f}% of low compute users {want}\")\n",
        "\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNyZyke_deam",
        "outputId": "006c48a5-3d99-4f83-91f1-14a4de3169db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 45 high compute users (>$100,000).\n",
            "There are 57 low compute users (<=$1000).\n",
            "\n",
            "32 high compute users WantsCompute and 29 low compute users WantsCompute\n",
            "71.11% of high compute users WantsCompute and 50.88% of low compute users WantsCompute\n",
            "\n",
            "25 high compute users WantsData and 28 low compute users WantsData\n",
            "55.56% of high compute users WantsData and 49.12% of low compute users WantsData\n",
            "\n",
            "17 high compute users WantsStaff and 18 low compute users WantsStaff\n",
            "37.78% of high compute users WantsStaff and 31.58% of low compute users WantsStaff\n",
            "\n",
            "29 high compute users WantsGrants and 43 low compute users WantsGrants\n",
            "64.44% of high compute users WantsGrants and 75.44% of low compute users WantsGrants\n",
            "\n",
            "16 high compute users WantsStandards and 15 low compute users WantsStandards\n",
            "35.56% of high compute users WantsStandards and 26.32% of low compute users WantsStandards\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# high and low compute user preferences\n",
        "for priority in [\"Compute\", \"Talent\", \"Data\"]:\n",
        "  print(f\"The # of high compute users who would prioritize {priority} is {len(high_compute_users[high_compute_users.PrioritySimplified == priority])} and the # of low compute users is {len(low_compute_users[low_compute_users.PrioritySimplified == priority])}\")\n",
        "print(\"\\n-----\\n\")\n",
        "for success in [\"SuccessData\", \"SuccessTeamSize\", \"SuccessTalent\", \"SuccessCompute\"]:\n",
        "  print(f\"The # of high compute users who attribute their success to {success[7:].lower()} is {len(high_compute_users[high_compute_users[success] >= 3])} and the # of low compute users is {len(low_compute_users[low_compute_users[success] >= 3])}\")\n",
        "print(\"\\n-----\\n\")\n",
        "for i, concern_level in enumerate([\"not at all concerned\", \"slightly_concerned\", \"somewhat concerned\", \"moderately concerned\", \"extremely concerned\"]):\n",
        "  print(f\"The # of high compute users whose concern level is {concern_level.replace('_', ' ')} is {len(high_compute_users[high_compute_users.ContributionConcern == i])} and the # of low compute users is {len(low_compute_users[low_compute_users.ContributionConcern == i])}\")\n",
        "  print(f\"The % of high compute users whose concern level is {concern_level.replace('_', ' ')} is {(len(high_compute_users[high_compute_users.ContributionConcern == i])/len(high_compute_users))*100:.2f}% and the % of low compute users is {(len(low_compute_users[low_compute_users.ContributionConcern == i])/len(low_compute_users))*100:.2f}%\")\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5kNqBTC1f33",
        "outputId": "983052ad-c9b9-4cd0-ff51-a4775af2da83"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The # of high compute users who would prioritize Compute is 23 and the # of low compute users is 7\n",
            "The # of high compute users who would prioritize Talent is 46 and the # of low compute users is 39\n",
            "The # of high compute users who would prioritize Data is 15 and the # of low compute users is 14\n",
            "\n",
            "-----\n",
            "\n",
            "The # of high compute users who attribute their success to data is 41 and the # of low compute users is 24\n",
            "The # of high compute users who attribute their success to teamsize is 19 and the # of low compute users is 7\n",
            "The # of high compute users who attribute their success to talent is 79 and the # of low compute users is 60\n",
            "The # of high compute users who attribute their success to compute is 60 and the # of low compute users is 27\n",
            "\n",
            "-----\n",
            "\n",
            "The # of high compute users whose concern level is not at all concerned is 13 and the # of low compute users is 25\n",
            "The % of high compute users whose concern level is not at all concerned is 14.77% and the % of low compute users is 35.71%\n",
            "\n",
            "The # of high compute users whose concern level is slightly concerned is 13 and the # of low compute users is 10\n",
            "The % of high compute users whose concern level is slightly concerned is 14.77% and the % of low compute users is 14.29%\n",
            "\n",
            "The # of high compute users whose concern level is somewhat concerned is 20 and the # of low compute users is 16\n",
            "The % of high compute users whose concern level is somewhat concerned is 22.73% and the % of low compute users is 22.86%\n",
            "\n",
            "The # of high compute users whose concern level is moderately concerned is 21 and the # of low compute users is 9\n",
            "The % of high compute users whose concern level is moderately concerned is 23.86% and the % of low compute users is 12.86%\n",
            "\n",
            "The # of high compute users whose concern level is extremely concerned is 17 and the # of low compute users is 3\n",
            "The % of high compute users whose concern level is extremely concerned is 19.32% and the % of low compute users is 4.29%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Language Modeling"
      ],
      "metadata": {
        "id": "dQJ4Dnf-I99E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlpers = version[version.NLP == 1]\n",
        "language_modelers = version[version.LanguageModeling == 1]\n",
        "non_model_nlpers = version[(version.LanguageModeling) == 0 & (version.NLP == 1)]\n",
        "print(f\"There are {len(nlpers)} NLP respondents.\")\n",
        "print(f\"There are {len(language_modelers)} language modeling respondents.\")\n",
        "print(f\"There are {len(language_modelers)} NLP respondents who report that they do not do language modeling.\")\n",
        "print(\"\\n-----\\n\")\n",
        "\n",
        "for sector in [\"Academia\", \"Industry\"]:\n",
        "  print(f\"The # of language modelers in {sector} is {len(language_modelers[language_modelers.Sector == sector])} while the # of NLP respondents is {len(nlpers[nlpers.Sector == sector])} and the # of non-language-model NLPers is {len(non_model_nlpers[non_model_nlpers.Sector == sector])}\")\n",
        "  print(f\"The % of {sector} respondents among language modelers is {(len(language_modelers[language_modelers.Sector == sector])/len(language_modelers))*100:.2f}% while the % among NLP respondents is {(len(nlpers[nlpers.Sector == sector])/len(nlpers))*100:.2f}%\")\n",
        "  print()\n",
        "print(\"-----\\n\")\n",
        "for i, computeuse in enumerate([\"no\", \"50 or fewer\", \"51-500\", \"501-5000\", \"5001-50,000\", \"50,001-500,000\", \"more than 500,000\", \"an unknown number of\"]):\n",
        "  print(f\"The # of language modelers who report using {computeuse} GPUs is {len(language_modelers[language_modelers.CompGPUs == i])} while the # of NLP respondents is {len(nlpers[nlpers.CompGPUs == i])} and the # of non-language-model NLPers is {len(non_model_nlpers[non_model_nlpers.CompGPUs == i])}\")\n",
        "  print(f\"The % of language modelers who report using {computeuse} GPUs is {(len(language_modelers[language_modelers.CompGPUs == i])/len(language_modelers))*100:.2f}% while the % of NLP respondents is {(len(nlpers[nlpers.CompGPUs == i])/len(nlpers))*100:.2f}%\")\n",
        "  print()\n",
        "print(\"-----\\n\")\n",
        "for i, computeuse in enumerate([\"$0\", \"$1-$1000\", \"$1,001-$10,000\", \"$10,001-$100,000\", \"$100,001-$1,000,000\", \"more than $1,000,000\", \"an unknown amount of\"]):\n",
        "  print(f\"The # of language modelers who report using {computeuse} money is {len(language_modelers[language_modelers.CompCost == i])} while the # of NLP respondents is {len(nlpers[nlpers.CompCost == i])} and the # of non-language-model NLPers is {len(non_model_nlpers[non_model_nlpers.CompCost == i])} \")\n",
        "  print(f\"The % of language modelers who report using {computeuse} money is {(len(language_modelers[language_modelers.CompCost == i])/len(language_modelers))*100:.2f}% while the % of NLP respondents is {(len(nlpers[nlpers.CompCost == i])/len(nlpers))*100:.2f}%\")\n",
        "  print()\n",
        "print(\"-----\\n\")\n",
        "for past in [\"PastData\", \"PastCompute\", \"PastAlgorithms\", \"PastResearchers\", \"PastSupport\"]:\n",
        "  print(f\"The # of language modelers who report {past[4:].lower()} as important to past progress is {len(language_modelers[language_modelers[past] == 4])} while the # of NLP respondents is {len(nlpers[nlpers[past] == 4])} and the # of non-language-model NLPers is {len(non_model_nlpers[non_model_nlpers[past] == 4])}\")\n",
        "  print(f\"The % of language modelers who report {past[4:].lower()} as important to past progress is {(len(language_modelers[language_modelers[past] >= 3])/len(language_modelers))*100:.2f}% while the % of NLP respondents is {(len(nlpers[nlpers[past] >= 3])/len(nlpers))*100:.2f}%\")\n",
        "  print()\n",
        "print(\"-----\\n\")\n",
        "for future in [\"FutureData\", \"FutureCompute\", \"FutureAlgorithms\", \"FutureResearchers\", \"FutureSupport\"]:\n",
        "  print(f\"The # of language modelers who report {future[6:].lower()} as important to future progress is {len(language_modelers[language_modelers[future] == 4])} while the # of NLP respondents is {len(nlpers[nlpers[future] == 4])} and the # of non-language-model NLPers is {len(non_model_nlpers[non_model_nlpers[future] == 4])}\")\n",
        "  print(f\"The % of language modelers who report {future[6:].lower()} as important to future progress is {(len(language_modelers[language_modelers[future] == 4])/len(language_modelers))*100:.2f}% while the % of NLP respondents is {(len(nlpers[nlpers[future] == 4])/len(nlpers))*100:.2f}%\")\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PETZg-vCcT-",
        "outputId": "cdfcf126-f006-45e4-8f29-75c43ae22be0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 143 NLP respondents.\n",
            "There are 70 language modeling respondents.\n",
            "There are 70 NLP respondents who report that they do not do language modeling.\n",
            "\n",
            "-----\n",
            "\n",
            "The # of language modelers in Academia is 40 while the # of NLP respondents is 83 and the # of non-language-model NLPers is 42\n",
            "The % of Academia respondents among language modelers is 57.14% while the % among NLP respondents is 58.04%\n",
            "\n",
            "The # of language modelers in Industry is 28 while the # of NLP respondents is 58 and the # of non-language-model NLPers is 28\n",
            "The % of Industry respondents among language modelers is 40.00% while the % among NLP respondents is 40.56%\n",
            "\n",
            "-----\n",
            "\n",
            "The # of language modelers who report using no GPUs is 0 while the # of NLP respondents is 4 and the # of non-language-model NLPers is 4\n",
            "The % of language modelers who report using no GPUs is 0.00% while the % of NLP respondents is 2.80%\n",
            "\n",
            "The # of language modelers who report using 50 or fewer GPUs is 3 while the # of NLP respondents is 7 and the # of non-language-model NLPers is 4\n",
            "The % of language modelers who report using 50 or fewer GPUs is 4.29% while the % of NLP respondents is 4.90%\n",
            "\n",
            "The # of language modelers who report using 51-500 GPUs is 17 while the # of NLP respondents is 32 and the # of non-language-model NLPers is 14\n",
            "The % of language modelers who report using 51-500 GPUs is 24.29% while the % of NLP respondents is 22.38%\n",
            "\n",
            "The # of language modelers who report using 501-5000 GPUs is 18 while the # of NLP respondents is 33 and the # of non-language-model NLPers is 15\n",
            "The % of language modelers who report using 501-5000 GPUs is 25.71% while the % of NLP respondents is 23.08%\n",
            "\n",
            "The # of language modelers who report using 5001-50,000 GPUs is 11 while the # of NLP respondents is 19 and the # of non-language-model NLPers is 8\n",
            "The % of language modelers who report using 5001-50,000 GPUs is 15.71% while the % of NLP respondents is 13.29%\n",
            "\n",
            "The # of language modelers who report using 50,001-500,000 GPUs is 6 while the # of NLP respondents is 10 and the # of non-language-model NLPers is 3\n",
            "The % of language modelers who report using 50,001-500,000 GPUs is 8.57% while the % of NLP respondents is 6.99%\n",
            "\n",
            "The # of language modelers who report using more than 500,000 GPUs is 4 while the # of NLP respondents is 4 and the # of non-language-model NLPers is 0\n",
            "The % of language modelers who report using more than 500,000 GPUs is 5.71% while the % of NLP respondents is 2.80%\n",
            "\n",
            "The # of language modelers who report using an unknown number of GPUs is 0 while the # of NLP respondents is 0 and the # of non-language-model NLPers is 0\n",
            "The % of language modelers who report using an unknown number of GPUs is 0.00% while the % of NLP respondents is 0.00%\n",
            "\n",
            "-----\n",
            "\n",
            "The # of language modelers who report using $0 money is 2 while the # of NLP respondents is 5 and the # of non-language-model NLPers is 3 \n",
            "The % of language modelers who report using $0 money is 2.86% while the % of NLP respondents is 3.50%\n",
            "\n",
            "The # of language modelers who report using $1-$1000 money is 4 while the # of NLP respondents is 8 and the # of non-language-model NLPers is 4 \n",
            "The % of language modelers who report using $1-$1000 money is 5.71% while the % of NLP respondents is 5.59%\n",
            "\n",
            "The # of language modelers who report using $1,001-$10,000 money is 9 while the # of NLP respondents is 24 and the # of non-language-model NLPers is 15 \n",
            "The % of language modelers who report using $1,001-$10,000 money is 12.86% while the % of NLP respondents is 16.78%\n",
            "\n",
            "The # of language modelers who report using $10,001-$100,000 money is 16 while the # of NLP respondents is 29 and the # of non-language-model NLPers is 12 \n",
            "The % of language modelers who report using $10,001-$100,000 money is 22.86% while the % of NLP respondents is 20.28%\n",
            "\n",
            "The # of language modelers who report using $100,001-$1,000,000 money is 4 while the # of NLP respondents is 8 and the # of non-language-model NLPers is 4 \n",
            "The % of language modelers who report using $100,001-$1,000,000 money is 5.71% while the % of NLP respondents is 5.59%\n",
            "\n",
            "The # of language modelers who report using more than $1,000,000 money is 3 while the # of NLP respondents is 3 and the # of non-language-model NLPers is 0 \n",
            "The % of language modelers who report using more than $1,000,000 money is 4.29% while the % of NLP respondents is 2.10%\n",
            "\n",
            "The # of language modelers who report using an unknown amount of money is 0 while the # of NLP respondents is 0 and the # of non-language-model NLPers is 0 \n",
            "The % of language modelers who report using an unknown amount of money is 0.00% while the % of NLP respondents is 0.00%\n",
            "\n",
            "-----\n",
            "\n",
            "The # of language modelers who report data as important to past progress is 35 while the # of NLP respondents is 74 and the # of non-language-model NLPers is 38\n",
            "The % of language modelers who report data as important to past progress is 88.57% while the % of NLP respondents is 87.41%\n",
            "\n",
            "The # of language modelers who report compute as important to past progress is 50 while the # of NLP respondents is 94 and the # of non-language-model NLPers is 41\n",
            "The % of language modelers who report compute as important to past progress is 95.71% while the % of NLP respondents is 92.31%\n",
            "\n",
            "The # of language modelers who report algorithms as important to past progress is 23 while the # of NLP respondents is 42 and the # of non-language-model NLPers is 16\n",
            "The % of language modelers who report algorithms as important to past progress is 74.29% while the % of NLP respondents is 71.33%\n",
            "\n",
            "The # of language modelers who report researchers as important to past progress is 23 while the # of NLP respondents is 44 and the # of non-language-model NLPers is 20\n",
            "The % of language modelers who report researchers as important to past progress is 67.14% while the % of NLP respondents is 71.33%\n",
            "\n",
            "The # of language modelers who report support as important to past progress is 23 while the # of NLP respondents is 45 and the # of non-language-model NLPers is 20\n",
            "The % of language modelers who report support as important to past progress is 75.71% while the % of NLP respondents is 77.62%\n",
            "\n",
            "-----\n",
            "\n",
            "The # of language modelers who report data as important to future progress is 32 while the # of NLP respondents is 61 and the # of non-language-model NLPers is 27\n",
            "The % of language modelers who report data as important to future progress is 45.71% while the % of NLP respondents is 42.66%\n",
            "\n",
            "The # of language modelers who report compute as important to future progress is 37 while the # of NLP respondents is 62 and the # of non-language-model NLPers is 23\n",
            "The % of language modelers who report compute as important to future progress is 52.86% while the % of NLP respondents is 43.36%\n",
            "\n",
            "The # of language modelers who report algorithms as important to future progress is 38 while the # of NLP respondents is 69 and the # of non-language-model NLPers is 28\n",
            "The % of language modelers who report algorithms as important to future progress is 54.29% while the % of NLP respondents is 48.25%\n",
            "\n",
            "The # of language modelers who report researchers as important to future progress is 25 while the # of NLP respondents is 41 and the # of non-language-model NLPers is 14\n",
            "The % of language modelers who report researchers as important to future progress is 35.71% while the % of NLP respondents is 28.67%\n",
            "\n",
            "The # of language modelers who report support as important to future progress is 28 while the # of NLP respondents is 57 and the # of non-language-model NLPers is 27\n",
            "The % of language modelers who report support as important to future progress is 40.00% while the % of NLP respondents is 39.86%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Smaller companies"
      ],
      "metadata": {
        "id": "h3SSVNbwrsiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "smaller_industry = version[((version.CompanySize == '<50 Employees') | (version.CompanySize == '50-100 Employees') | (version.CompanySize == '101-500 Employees')) & (version.Sector == \"Industry\")]\n",
        "print(f\"There are {len(smaller_industry)} smaller company respondents.\")\n",
        "print(\"\\n-----\\n\")\n",
        "for field in [\"CV\", \"NLP\", \"Robotics\", \"RL\", \"Other\"]:\n",
        "  print(f\"The # of smaller company respondents in {field} is {len(smaller_industry[smaller_industry [field] == 1])} and the # of all users is {len(version[version[field] == 1])}\")\n",
        "  print(f\"The % of smaller company respondents in {field} is {(len(smaller_industry[smaller_industry [field] == 1])/len(smaller_industry))*100:.2f}% and the % of all users is {(len(version[version[field] == 1])/len(version))*100:.2f}%\")\n",
        "  print()\n",
        "print(\"-----\\n\")\n",
        "for priority in [\"Compute\", \"Talent\", \"Data\"]:\n",
        "  print(f\"The # of smaller company respondents who would prioritize {priority} is {len(smaller_industry[smaller_industry.PrioritySimplified == priority])} and the # of all users is {len(version[version.PrioritySimplified == priority])}\")\n",
        "  print(f\"The % of smaller company respondents who would prioritize {priority} is {(len(smaller_industry[smaller_industry.PrioritySimplified == priority])/len(smaller_industry))*100:.2f}% and the % of all users is {(len(version[version.PrioritySimplified == priority])/len(version))*100:.2f}%\")\n",
        "  print()\n",
        "print(\"-----\\n\")\n",
        "for success in [\"SuccessData\", \"SuccessTeamSize\", \"SuccessTalent\", \"SuccessCompute\"]:\n",
        "  print(f\"The # of smaller company respondents who attribute their success to {success[7:].lower()} is {len(smaller_industry[smaller_industry[success] >= 3])} and the # of all users is {len(version[version[success] >= 3])}\")\n",
        "  print(f\"The % of smaller company respondents who attribute their success to {success[7:].lower()} is {(len(smaller_industry[smaller_industry[success] >= 3])/len(smaller_industry))*100:.2f}% and the % of all users is {(len(version[version[success] >= 3])/len(version))*100:.2f}%\")\n",
        "  print()\n",
        "print(\"-----\\n\")\n",
        "for i, concern_level in enumerate([\"not at all concerned\", \"slightly_concerned\", \"somewhat concerned\", \"moderately concerned\", \"extremely concerned\"]):\n",
        "  print(f\"The # of smaller company respondents whose concern level is {concern_level.replace('_', ' ')} is {len(smaller_industry[smaller_industry.ContributionConcern == i])} and the # of all users is {len(version[version.ContributionConcern == i])}\")\n",
        "  print(f\"The % of smaller company respondents whose concern level is {concern_level.replace('_', ' ')} is {(len(smaller_industry[smaller_industry.ContributionConcern == i])/len(smaller_industry))*100:.2f}% and the % of all users is {(len(version[version.ContributionConcern == i])/len(version))*100:.2f}%\")\n",
        "  print()\n",
        "#concern with nonresponses dropped\n",
        "print(\"-----\\n\")\n",
        "print(\"With nonresponse dropped\")\n",
        "nonresponse_dropped = version.dropna(subset=[\"ContributionConcern\"])\n",
        "smaller_industry_dropped = nonresponse_dropped[(nonresponse_dropped.CompanySize == '<50 Employees') | (nonresponse_dropped.CompanySize == '50-100 Employees') | (nonresponse_dropped.CompanySize == '101-500 Employees')]\n",
        "for i, concern_level in enumerate([\"not at all concerned\", \"slightly_concerned\", \"somewhat concerned\", \"moderately concerned\", \"extremely concerned\"]):\n",
        "  print(f\"The # of smaller company respondents whose concern level is {concern_level.replace('_', ' ')} is {len(smaller_industry_dropped[smaller_industry_dropped.ContributionConcern == i])} and the # of all users is {len(nonresponse_dropped[nonresponse_dropped.ContributionConcern == i])}\")\n",
        "  print(f\"The % of smaller company respondents whose concern level is {concern_level.replace('_', ' ')} is {(len(smaller_industry_dropped[smaller_industry_dropped.ContributionConcern == i])/len(smaller_industry_dropped))*100:.2f}% and the % of all users is {(len(nonresponse_dropped[nonresponse_dropped.ContributionConcern == i])/len(nonresponse_dropped))*100:.2f}%\")\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3H8YCRng8aG",
        "outputId": "ac9af497-07ac-41de-cce3-58c874fdcbb1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 35 smaller company respondents.\n",
            "\n",
            "-----\n",
            "\n",
            "The # of smaller company respondents in CV is 14 and the # of all users is 150\n",
            "The % of smaller company respondents in CV is 40.00% and the % of all users is 28.14%\n",
            "\n",
            "The # of smaller company respondents in NLP is 16 and the # of all users is 143\n",
            "The % of smaller company respondents in NLP is 45.71% and the % of all users is 26.83%\n",
            "\n",
            "The # of smaller company respondents in Robotics is 7 and the # of all users is 72\n",
            "The % of smaller company respondents in Robotics is 20.00% and the % of all users is 13.51%\n",
            "\n",
            "The # of smaller company respondents in RL is 5 and the # of all users is 81\n",
            "The % of smaller company respondents in RL is 14.29% and the % of all users is 15.20%\n",
            "\n",
            "The # of smaller company respondents in Other is 9 and the # of all users is 160\n",
            "The % of smaller company respondents in Other is 25.71% and the % of all users is 30.02%\n",
            "\n",
            "-----\n",
            "\n",
            "The # of smaller company respondents who would prioritize Compute is 4 and the # of all users is 88\n",
            "The % of smaller company respondents who would prioritize Compute is 11.43% and the % of all users is 16.51%\n",
            "\n",
            "The # of smaller company respondents who would prioritize Talent is 15 and the # of all users is 223\n",
            "The % of smaller company respondents who would prioritize Talent is 42.86% and the % of all users is 41.84%\n",
            "\n",
            "The # of smaller company respondents who would prioritize Data is 14 and the # of all users is 93\n",
            "The % of smaller company respondents who would prioritize Data is 40.00% and the % of all users is 17.45%\n",
            "\n",
            "-----\n",
            "\n",
            "The # of smaller company respondents who attribute their success to data is 20 and the # of all users is 213\n",
            "The % of smaller company respondents who attribute their success to data is 57.14% and the % of all users is 39.96%\n",
            "\n",
            "The # of smaller company respondents who attribute their success to teamsize is 4 and the # of all users is 70\n",
            "The % of smaller company respondents who attribute their success to teamsize is 11.43% and the % of all users is 13.13%\n",
            "\n",
            "The # of smaller company respondents who attribute their success to talent is 26 and the # of all users is 372\n",
            "The % of smaller company respondents who attribute their success to talent is 74.29% and the % of all users is 69.79%\n",
            "\n",
            "The # of smaller company respondents who attribute their success to compute is 14 and the # of all users is 214\n",
            "The % of smaller company respondents who attribute their success to compute is 40.00% and the % of all users is 40.15%\n",
            "\n",
            "-----\n",
            "\n",
            "The # of smaller company respondents whose concern level is not at all concerned is 14 and the # of all users is 89\n",
            "The % of smaller company respondents whose concern level is not at all concerned is 40.00% and the % of all users is 16.70%\n",
            "\n",
            "The # of smaller company respondents whose concern level is slightly concerned is 6 and the # of all users is 80\n",
            "The % of smaller company respondents whose concern level is slightly concerned is 17.14% and the % of all users is 15.01%\n",
            "\n",
            "The # of smaller company respondents whose concern level is somewhat concerned is 6 and the # of all users is 80\n",
            "The % of smaller company respondents whose concern level is somewhat concerned is 17.14% and the % of all users is 15.01%\n",
            "\n",
            "The # of smaller company respondents whose concern level is moderately concerned is 5 and the # of all users is 106\n",
            "The % of smaller company respondents whose concern level is moderately concerned is 14.29% and the % of all users is 19.89%\n",
            "\n",
            "The # of smaller company respondents whose concern level is extremely concerned is 4 and the # of all users is 57\n",
            "The % of smaller company respondents whose concern level is extremely concerned is 11.43% and the % of all users is 10.69%\n",
            "\n",
            "-----\n",
            "\n",
            "With nonresponse dropped\n",
            "The # of smaller company respondents whose concern level is not at all concerned is 14 and the # of all users is 89\n",
            "The % of smaller company respondents whose concern level is not at all concerned is 35.90% and the % of all users is 21.60%\n",
            "\n",
            "The # of smaller company respondents whose concern level is slightly concerned is 7 and the # of all users is 80\n",
            "The % of smaller company respondents whose concern level is slightly concerned is 17.95% and the % of all users is 19.42%\n",
            "\n",
            "The # of smaller company respondents whose concern level is somewhat concerned is 7 and the # of all users is 80\n",
            "The % of smaller company respondents whose concern level is somewhat concerned is 17.95% and the % of all users is 19.42%\n",
            "\n",
            "The # of smaller company respondents whose concern level is moderately concerned is 7 and the # of all users is 106\n",
            "The % of smaller company respondents whose concern level is moderately concerned is 17.95% and the % of all users is 25.73%\n",
            "\n",
            "The # of smaller company respondents whose concern level is extremely concerned is 4 and the # of all users is 57\n",
            "The % of smaller company respondents whose concern level is extremely concerned is 10.26% and the % of all users is 13.83%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cloud Computing"
      ],
      "metadata": {
        "id": "ptY0r5OUqKNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "academics = version[version.Sector == \"Academia\"]\n",
        "cloud = academics[academics.CloudUser == 1]\n",
        "cloud_only = cloud[cloud.OnPremise == 0]\n",
        "print(f\"There are {len(academics)} academics.\")\n",
        "print(f\"There are {len(cloud)} academics who use cloud computing.\")\n",
        "print(f\"There are {len(cloud_only)} academics who only use cloud computing.\")\n",
        "print(\"\\n-----\\n\")\n",
        "for field in [\"CV\", \"NLP\", \"Robotics\", \"RL\", \"Other\"]:\n",
        "  print(f\"The # of cloud respondents in {field} is {len(cloud[cloud[field] == 1])} and the # of cloud only respondents is {len(cloud_only[cloud_only[field] == 1])} and the number of academic respondents is {len(academics[academics[field] == 1])}\")\n",
        "  print(f\"The % of cloud respondents in {field} is {(len(cloud[cloud[field] == 1])/len(cloud))*100:.2f}% and the % of cloud only respondents is {(len(cloud_only[cloud_only[field] == 1])/len(cloud_only))*100:.2f}% and the % of academic respondents is {(len(academics[academics[field] == 1])/len(academics))*100:.2f}%\")\n",
        "  print()\n",
        "print(\"-----\\n\")\n",
        "for priority in [\"Compute\", \"Talent\", \"Data\"]:\n",
        "  print(f\"The # of cloud respondents who would prioritize {priority} is {len(cloud[cloud.PrioritySimplified == priority])} and the # of cloud only respondents is {len(cloud_only[cloud_only.PrioritySimplified == priority])} and the # of academic respondents is {len(academics[academics.PrioritySimplified == priority])}\")\n",
        "  print(f\"The % of cloud respondents who would  prioritize {priority} is {(len(cloud[cloud.PrioritySimplified == priority])/len(cloud))*100:.2f}% and the % of cloud only respondents is {(len(cloud_only[cloud_only.PrioritySimplified == priority])/len(cloud_only))*100:.2f}% and the % of academic respondents is {(len(academics[academics.PrioritySimplified == priority])/len(academics))*100:.2f}%\")\n",
        "  print()\n",
        "print(\"-----\\n\")\n",
        "for i, concern_level in enumerate([\"not at all concerned\", \"slightly_concerned\", \"somewhat concerned\", \"moderately concerned\", \"extremely concerned\"]):\n",
        "  print(f\"The # of cloud respondents whose concern level is {concern_level.replace('_', ' ')} is {len(cloud[cloud.ContributionConcern == i])} and the # of cloud only respondents is {len(cloud_only[cloud_only.ContributionConcern == i])} and the # of academic respondents is {len(academics[academics.ContributionConcern == i])}\")\n",
        "  print(f\"The % of cloud respondents whose concern level is {concern_level.replace('_', ' ')} is {(len(cloud[cloud.ContributionConcern == i])/len(cloud))*100:.2f}% and the % of cloud only respondents is {(len(cloud_only[cloud_only.ContributionConcern == i])/len(cloud_only))*100:.2f}% and the % of academic respondents is {(len(academics[academics.ContributionConcern == i])/len(academics))*100:.2f}%\")\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFvskL6E0PeM",
        "outputId": "318110a9-bf7e-4375-80dd-d204d12c6576"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 274 academics.\n",
            "There are 138 academics who use cloud computing.\n",
            "There are 40 academics who only use cloud computing.\n",
            "\n",
            "-----\n",
            "\n",
            "The # of cloud respondents in CV is 41 and the # of cloud only respondents is 14 and the number of academic respondents is 95\n",
            "The % of cloud respondents in CV is 29.71% and the % of cloud only respondents is 35.00% and the % of academic respondents is 34.67%\n",
            "\n",
            "The # of cloud respondents in NLP is 44 and the # of cloud only respondents is 16 and the number of academic respondents is 83\n",
            "The % of cloud respondents in NLP is 31.88% and the % of cloud only respondents is 40.00% and the % of academic respondents is 30.29%\n",
            "\n",
            "The # of cloud respondents in Robotics is 27 and the # of cloud only respondents is 2 and the number of academic respondents is 58\n",
            "The % of cloud respondents in Robotics is 19.57% and the % of cloud only respondents is 5.00% and the % of academic respondents is 21.17%\n",
            "\n",
            "The # of cloud respondents in RL is 31 and the # of cloud only respondents is 7 and the number of academic respondents is 59\n",
            "The % of cloud respondents in RL is 22.46% and the % of cloud only respondents is 17.50% and the % of academic respondents is 21.53%\n",
            "\n",
            "The # of cloud respondents in Other is 60 and the # of cloud only respondents is 23 and the number of academic respondents is 107\n",
            "The % of cloud respondents in Other is 43.48% and the % of cloud only respondents is 57.50% and the % of academic respondents is 39.05%\n",
            "\n",
            "-----\n",
            "\n",
            "The # of cloud respondents who would prioritize Compute is 31 and the # of cloud only respondents is 16 and the # of academic respondents is 64\n",
            "The % of cloud respondents who would  prioritize Compute is 22.46% and the % of cloud only respondents is 40.00% and the % of academic respondents is 23.36%\n",
            "\n",
            "The # of cloud respondents who would prioritize Talent is 76 and the # of cloud only respondents is 16 and the # of academic respondents is 145\n",
            "The % of cloud respondents who would  prioritize Talent is 55.07% and the % of cloud only respondents is 40.00% and the % of academic respondents is 52.92%\n",
            "\n",
            "The # of cloud respondents who would prioritize Data is 21 and the # of cloud only respondents is 5 and the # of academic respondents is 46\n",
            "The % of cloud respondents who would  prioritize Data is 15.22% and the % of cloud only respondents is 12.50% and the % of academic respondents is 16.79%\n",
            "\n",
            "-----\n",
            "\n",
            "The # of cloud respondents whose concern level is not at all concerned is 26 and the # of cloud only respondents is 5 and the # of academic respondents is 52\n",
            "The % of cloud respondents whose concern level is not at all concerned is 18.84% and the % of cloud only respondents is 12.50% and the % of academic respondents is 18.98%\n",
            "\n",
            "The # of cloud respondents whose concern level is slightly concerned is 22 and the # of cloud only respondents is 6 and the # of academic respondents is 52\n",
            "The % of cloud respondents whose concern level is slightly concerned is 15.94% and the % of cloud only respondents is 15.00% and the % of academic respondents is 18.98%\n",
            "\n",
            "The # of cloud respondents whose concern level is somewhat concerned is 29 and the # of cloud only respondents is 9 and the # of academic respondents is 57\n",
            "The % of cloud respondents whose concern level is somewhat concerned is 21.01% and the % of cloud only respondents is 22.50% and the % of academic respondents is 20.80%\n",
            "\n",
            "The # of cloud respondents whose concern level is moderately concerned is 39 and the # of cloud only respondents is 9 and the # of academic respondents is 72\n",
            "The % of cloud respondents whose concern level is moderately concerned is 28.26% and the % of cloud only respondents is 22.50% and the % of academic respondents is 26.28%\n",
            "\n",
            "The # of cloud respondents whose concern level is extremely concerned is 22 and the # of cloud only respondents is 11 and the # of academic respondents is 41\n",
            "The % of cloud respondents whose concern level is extremely concerned is 15.94% and the % of cloud only respondents is 27.50% and the % of academic respondents is 14.96%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LGe3EYMCrEx1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}